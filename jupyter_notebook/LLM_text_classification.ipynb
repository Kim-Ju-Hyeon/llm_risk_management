{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13cc155-aa30-4387-a577-69ed7b0bf041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800ba7fe-8194-4777-a825-bee7807ad476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, pipeline, AutoModelForSequenceClassification\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "\n",
    "from utils.util_fnc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5124eb0-2915-4d9e-bb82-abf30c877115",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "huggingface_token = os.getenv(\"huggingface_token\")\n",
    "openai_key = os.getenv(\"open_ai_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75cf85ec-f49e-4eb6-87c4-3b2687ea836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_yaml('../src/config/text_classification_config.yaml')\n",
    "prompt_dict = load_yaml(os.path.join(config.root_dir, 'prompt', 'first_step_prompt.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b80dd98-a2d8-4069-9c86-08d164dd32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_text = pd.read_csv(os.path.join(config.root_dir, 'data', 'dummy_articles', 'articles.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe7a082b-f8f7-4f58-8671-520a55d36279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "if config.model == 'lamma2':\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name, token=huggingface_token)\n",
    "\n",
    "    if torch.cuda.is_available() and 'cuda' in config.device:\n",
    "        torch_dtype = torch.float16\n",
    "    else:\n",
    "        config.device = 'cpu'\n",
    "        torch_dtype = torch.float32\n",
    "            \n",
    "    pipeline = transformers.pipeline(\n",
    "        config.task,\n",
    "        model=config.model_name,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=config.device\n",
    "    )\n",
    "\n",
    "elif config.model == 'gpt3.5':\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Not supported model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f0ab450-776d-4ff1-819c-355c6b1708ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(x, config):\n",
    "    if config.model == 'lamma2':\n",
    "        x = '\\n'.join(x)\n",
    "        sequences = pipeline(x, **config.lamma_config)\n",
    "        return sequences[0]['generated_text'].replace(x, \"\")\n",
    "        \n",
    "    elif config.model == 'gpt3.5':\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": '\\n'.join(x[:3])},\n",
    "            {\"role\": \"assistant\", \"content\": x[3]},\n",
    "            {\"role\": \"user\", \"content\": x[4]}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(**config.openai_config, messages=messages)\n",
    "        return response['choices'][0]['text']\n",
    "    else:\n",
    "        raise ValueError(\"Not a supported model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b011dc75-373e-40b2-8b15-814d2c01dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_text(article, prompt_dict, config):\n",
    "    start_time = time.time()\n",
    "    elapsed_time = 0\n",
    "\n",
    "    while elapsed_time < config.time_limit:\n",
    "        # Generate input and get the model's answer\n",
    "        input_text = generate_input_text(prompt_dict, article)\n",
    "        gen_text = answer(input_text, config)\n",
    "        \n",
    "        cleaned_output = cleaning_text(gen_text)\n",
    "        if len(cleaned_output) >= 500:\n",
    "            continue\n",
    "\n",
    "        # Check for True or False in the output\n",
    "        if \"True\" in cleaned_output and \"False\" not in cleaned_output:\n",
    "            return True, cleaned_output\n",
    "        elif \"False\" in cleaned_output and \"True\" not in cleaned_output:\n",
    "            return False, cleaned_output\n",
    "\n",
    "        # Update elapsed time\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Reached time limit without a definitive answer\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b2eb9c-4e93-4849-99cc-3aa295a8b8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "cleaned_output_dict = {}\n",
    "\n",
    "for index, row in dummy_text.iterrows():\n",
    "    # Clean the article text\n",
    "    article = re.sub(r'[^\\w\\s]', '', row.Content).strip()\n",
    "\n",
    "    # Evaluate the text\n",
    "    output, cleaned_output = evaluate_text(article, prompt_dict, config)\n",
    "\n",
    "    result_dict[index] = f'{row.Category}: ' + str(output)\n",
    "    cleaned_output_dict[index] = cleaned_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba4be98e-c41d-4066-a3eb-9ab47db49de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Travel: False',\n",
       " 1: 'Technology: False',\n",
       " 2: 'Science: False',\n",
       " 3: 'Food and Cooking: False',\n",
       " 4: 'Literature: False',\n",
       " 5: 'Personal Development: False',\n",
       " 6: 'Entertainment: False',\n",
       " 7: 'Environmental Issues: False',\n",
       " 8: 'Art and Creativity: False',\n",
       " 9: 'Automotive: True',\n",
       " 10: 'Automotive: True',\n",
       " 11: 'Automotive: True'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eaf17fe-9ee8-4b4e-b4ec-344d1243d465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'False This article does not relate to the car business because there is no mention of cars or any other transportationrelated topics',\n",
       " 1: 'The text provided does not directly relate to the Automotives Domain It discusses Artificial intelligences application in the healthcare sector specifically focusing on imaging diagnostics clinical support systems drug discovery and personalized medicine While AI may have some indirect connections to autonomous vehicles or other automotivetechnologies there is no direct relationship between the content and the automobile industry Therefore my response is False',\n",
       " 2: 'False There is no mention of any aspect of the automobile industry in the provided text It discusses space explorations which does not fall under the purview of the auto mobile industry',\n",
       " 3: 'False The provided text does not relate to the car business or any other aspect of the automobile sector It discusses various plantbased cuisine recipes ingredients and cooking methods',\n",
       " 4: 'False This text does not relate to the car industry because there is no mention of cars or any other vehicle technology',\n",
       " 5: 'False Its not directly related to Automotive Domain but may have some indirect relation like GoalSetting techniques could be applied to improve production line efficiency or employee performance which might be useful for Automotives',\n",
       " 6: 'False This article does not relate to the car business because it discusses forthcoming films scheduled for release in ',\n",
       " 7: 'False There is no mention of any aspect of the automative industry within the provided text',\n",
       " 8: 'False While there may be cars mentioned in the article they do not play any central role in the topic of street arts evolution',\n",
       " 9: 'True This article discusses the expected increase in vehicle sales for HyundiaKia in',\n",
       " 10: 'True This text discusses the expansion of Hyundia Mobuss business in the United States specifically focusing on the growth of electric vehicle EV production As an attorney specializing in automotve law this text relates directly to the autmotive industry',\n",
       " 11: 'True Reason This article discusses a specific recall notice for certain models of Kia Sportage cars due to potential fire hazards which falls within the scope of the automobile industry'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda77f2-1906-4228-a0e4-e791e2cbd6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
