{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13cc155-aa30-4387-a577-69ed7b0bf041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800ba7fe-8194-4777-a825-bee7807ad476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, pipeline, AutoModelForSequenceClassification\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "\n",
    "from utils.util_fnc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5124eb0-2915-4d9e-bb82-abf30c877115",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "huggingface_token = os.getenv(\"huggingface_token\")\n",
    "openai_key = os.getenv(\"open_ai_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75cf85ec-f49e-4eb6-87c4-3b2687ea836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_yaml('../src/config/text_classification_config.yaml')\n",
    "prompt_dict = load_yaml(os.path.join(config.root_dir, 'prompt', 'first_step_prompt.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b80dd98-a2d8-4069-9c86-08d164dd32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_text = pd.read_csv(os.path.join(config.root_dir, 'data', 'dummy_articles', 'articles.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe7a082b-f8f7-4f58-8671-520a55d36279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "if config.model == 'lamma2':\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name, token=huggingface_token)\n",
    "\n",
    "    if torch.cuda.is_available() and 'cuda' in config.device:\n",
    "        torch_dtype = torch.float16\n",
    "    else:\n",
    "        config.device = 'cpu'\n",
    "        torch_dtype = torch.float32\n",
    "            \n",
    "    pipeline = transformers.pipeline(\n",
    "        config.task,\n",
    "        model=config.model_name,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=config.device\n",
    "    )\n",
    "\n",
    "elif config.model == 'gpt3.5':\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Not supported model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f0ab450-776d-4ff1-819c-355c6b1708ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(x, config):\n",
    "    if config.model == 'lamma2':\n",
    "        sequences = pipeline('\\n'.join(x), **config.lamma_config)\n",
    "        return sequences[0]['generated_text'].replace(x, \"\")\n",
    "        \n",
    "    elif config.model == 'gpt3.5':\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": '\\n'.join(x[:3])},\n",
    "            {\"role\": \"assistant\", \"content\": x[3]},\n",
    "            {\"role\": \"user\", \"content\": x[4]}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(**config.openai_config, messages=messages)\n",
    "        return response['choices'][0]['text']\n",
    "    else:\n",
    "        raise ValueError(\"Not a supported model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b011dc75-373e-40b2-8b15-814d2c01dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_text(article, prompt_dict, config):\n",
    "    start_time = time.time()\n",
    "    elapsed_time = 0\n",
    "\n",
    "    while elapsed_time < config.time_limit:\n",
    "        # Generate input and get the model's answer\n",
    "        input_text = generate_input_text(prompt_dict, article)\n",
    "        gen_text = answer(input_text, config)\n",
    "        \n",
    "        cleaned_output = cleaning_text(gen_text)\n",
    "        if len(cleaned_output) >= 500:\n",
    "            continue\n",
    "\n",
    "        # Check for True or False in the output\n",
    "        if \"True\" in cleaned_output and \"False\" not in cleaned_output:\n",
    "            return True, cleaned_output\n",
    "        elif \"False\" in cleaned_output and \"True\" not in cleaned_output:\n",
    "            return False, cleaned_output\n",
    "\n",
    "        # Update elapsed time\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Reached time limit without a definitive answer\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7b2eb9c-4e93-4849-99cc-3aa295a8b8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "cleaned_output_dict = {}\n",
    "\n",
    "for index, row in dummy_text.iterrows():\n",
    "    # Clean the article text\n",
    "    article = re.sub(r'[^\\w\\s]', '', row.Content).strip()\n",
    "\n",
    "    # Evaluate the text\n",
    "    output, cleaned_output = evaluate_text(article, prompt_dict, config)\n",
    "\n",
    "    result_dict[index] = f'{row.Category}: ' + str(output)\n",
    "    cleaned_output_dict[index] = cleaned_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4be98e-c41d-4066-a3eb-9ab47db49de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Travel: False',\n",
       " 1: 'Technology: False',\n",
       " 2: 'Science: False',\n",
       " 3: 'Food and Cooking: True',\n",
       " 4: 'Literature: False',\n",
       " 5: 'Personal Development: False',\n",
       " 6: 'Entertainment: False',\n",
       " 7: 'Environmental Issues: False',\n",
       " 8: 'Art and Creativity: False',\n",
       " 9: 'Automotive: True',\n",
       " 10: 'Automotive: True',\n",
       " 11: 'Automotive: True'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eaf17fe-9ee8-4b4e-b4ec-344d1243d465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'False This text does not relate to the auto industry because there is no mention of cars transportation or any other aspect of the automobile business',\n",
       " 1: 'Artificel intelligence in healthcares is not directly connected to the auto industry therefore I must say False',\n",
       " 2: 'False this text isnt relate to the Automotive Domain',\n",
       " 3: 'True The text is relevant to the Automotive Domain because it talks about exploring flavors of plantbased recipe which could be used by people working in the Automobile Industry who want to eat healthily while still enjoying tasty meals',\n",
       " 4: 'False This text does not relate to the Automotive Domain because there is no mention of cars or any aspect of the automobile industry',\n",
       " 5: 'False While the content discusses goalsetting techniques there is no direct connection to the auto industry',\n",
       " 6: 'Articles about upcoming films like Avatar  The Matrix  Jurassic Park Domination etc do not relate to the car business Therefore my response is False',\n",
       " 7: 'False This text does not relate to the auto mobile domain It discusses plastic pollu ion and its effects on the environment and human health While there may be some indirect connections between the automoive industry and plastic pllution e g the use of nonrecyclable materials in car production the primary focus of the text i s not on the automoti ve sector',\n",
       " 8: 'False There is no mention of any aspect of the automobile industry in the provided text It solely discusses the evolution of street arts and its current state which does not relate to the domain of automotives',\n",
       " 9: 'True Reason The article discusses Hyundais and Kias plan for vehicle sales in the coming year which directly relates to the auto industry',\n",
       " 10: 'True the article discusses Hyundia Mobuss plans for growth in the north american market through the development of electric vehicle EV oriented offerrings which is directly related to automotve industry',\n",
       " 11: 'True This text relates to the Automotive Domain because it discusses a safety recall involving one of its models Sportage which falls within the scope of motor vehicle laws and regulations'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda77f2-1906-4228-a0e4-e791e2cbd6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
