---
exp_name: text_classification
root_dir: 
save_dir:
dataset: MNT # OC, PJT, onm
device: cuda:0
model: meta-llama/Llama-2-7b-chat-hf  # gpt-3.5-turbo-1106, gpt-4-1106-preview

time_limit: 60 # Time limit for text classification (for each text) 

task: voc # onm : online negative monitoring

# This parameters is best option for our project (50% sure)
lamma_config:
    do_sample: True
    top_k: 10
    num_return_sequences: 1
    eos_token_id: 2  # Replace with model's eos_token_id 
    max_length: 4096
    temperature: 0.1 # high temperature make model's output diverse but we don't need it for our's project
    repetition_penalty: 1.2 
    no_repeat_ngram_size: 3
    top_p: 0.9

openai_config:
    model: gpt-3.5-turbo-1106 # gpt-4-1106-preview
    response_format: {"type": "json_object"}
    max_tokens: 2048 # 과도한 과금을 막기위해 입력 토큰 제한
    temperature: 0.2 # Higher value make the output more random -> deterministic한 결과를 얻기위해 낮은 값으로 설정
    top_p: 1.0
